{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForSequenceClassification, BertTokenizerFast, get_linear_schedule_with_warmup\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing randomness to get reproducible results\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 336\n",
      "\n",
      "Distribution of classes:\n",
      " label\n",
      "Politics         28\n",
      "Health           28\n",
      "Finance          28\n",
      "Travel           28\n",
      "Food             28\n",
      "Education        28\n",
      "Environment      28\n",
      "Fashion          28\n",
      "Science          28\n",
      "Sports           28\n",
      "Technology       28\n",
      "Entertainment    28\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from src.utils import load_data\n",
    "\n",
    "DATA_PATH = \"data/train_extended.json\"\n",
    "df = load_data(DATA_PATH)\n",
    "\n",
    "# Report the number of sentences.\n",
    "print('Number of sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "print('Distribution of classes:\\n', df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,\n",
       "        3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "        3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,\n",
       "        4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "        4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "        7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "        7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "        8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,\n",
       "        9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "        9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform labels in numbers\n",
    "unique_labels = df[\"label\"].unique()\n",
    "label_dict = {label: id for id, label in enumerate(unique_labels)}\n",
    "reverse_label_dict = {id: label for label, id in label_dict.items()}\n",
    "\n",
    "# Get the lists of sentences and their labels.\n",
    "sentences = df['text'].values\n",
    "labels = df['label'].apply(lambda x: label_dict[x]).values\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenise sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  The mayor announced a new initiative to improve public transportation.\n",
      "Tokenized:  ['the', 'mayor', 'announced', 'a', 'new', 'initiative', 'to', 'improve', 'public', 'transportation', '.']\n",
      "Token IDs:  [1996, 3664, 2623, 1037, 2047, 6349, 2000, 5335, 2270, 5193, 1012]\n"
     ]
    }
   ],
   "source": [
    "# Print the original sentence.\n",
    "print(' Original: ', sentences[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  23\n"
     ]
    }
   ],
   "source": [
    "print('Max sentence length: ', max([len(sen) for sen in tokenizer(sentences.tolist())['input_ids']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose a maximum sentence length of 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  The mayor announced a new initiative to improve public transportation.\n",
      "Token IDs: [101, 1996, 3664, 2623, 1037, 2047, 6349, 2000, 5335, 2270, 5193, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Attention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "#   (1) Tokenize the sentence.\n",
    "#   (2) Prepend the `[CLS]` token to the start.\n",
    "#   (3) Append the `[SEP]` token to the end.\n",
    "#   (4) Map tokens to their IDs.\n",
    "#   (5) Truncate or do padding to max_length if needed\n",
    "#   (6) Create the attention mask needed for the model\n",
    "tokenized = tokenizer(sentences.tolist(), padding=\"max_length\", max_length=MAX_LEN, truncation=True)\n",
    "input_ids = tokenized['input_ids']\n",
    "attention_masks = tokenized['attention_mask']\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])\n",
    "print('Attention mask:', attention_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_validation_split to split our data into train and validation sets for training\n",
    "# We use stratify to keep a good distribution in our train and validation sets\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(\n",
    "    input_ids, labels, test_size=0.33, stratify=labels\n",
    ")\n",
    "\n",
    "# Do the same for the masks.\n",
    "train_masks, validation_masks, _, _ = train_test_split(\n",
    "    attention_masks, labels, test_size=0.33, stratify=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to PyTorch data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all inputs and labels into torch tensors, the required datatype \n",
    "# for our model.\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here.\n",
    "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
    "# 16 or 32.\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = len(label_dict), # The number of output labels \n",
    "    output_attentions = False, # Whether the model returns attention weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# comment this to do fine-tuning, otherwise we do transfer learning\n",
    "# for name, param in model.named_parameters():\n",
    "# \tif 'classifier' not in name: # classifier layer\n",
    "# \t\tparam.requires_grad = False\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                          (12, 768)\n",
      "classifier.bias                                                (12,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, we set it at 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "EPOCHS = 50\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * EPOCHS\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Store the average loss after each epoch so we can plot them.\n",
    "# loss_values = []\n",
    "\n",
    "# # For each epoch...\n",
    "# for epoch_i in range(0, EPOCHS):\n",
    "    \n",
    "#     # ========================================\n",
    "#     #               Training\n",
    "#     # ========================================\n",
    "    \n",
    "#     # Perform one full pass over the training set.\n",
    "\n",
    "#     print(\"\")\n",
    "#     print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, EPOCHS))\n",
    "#     print('Training...')\n",
    "\n",
    "#     # Measure how long the training epoch takes.\n",
    "#     t0 = time.time()\n",
    "\n",
    "#     # Reset the total loss for this epoch.\n",
    "#     total_loss = 0\n",
    "\n",
    "#     # Put the model into training mode.\n",
    "#     model.train()\n",
    "\n",
    "#     # For each batch of training data...\n",
    "#     for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "#         # Progress update every 40 batches.\n",
    "#         if step % 40 == 0 and not step == 0:\n",
    "#             # Calculate elapsed time in minutes.\n",
    "#             elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "#             # Report progress.\n",
    "#             print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "#         # Unpack this training batch from our dataloader. \n",
    "#         #\n",
    "#         # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "#         # `to` method.\n",
    "#         #\n",
    "#         # `batch` contains three pytorch tensors:\n",
    "#         #   [0]: input ids \n",
    "#         #   [1]: attention masks\n",
    "#         #   [2]: labels \n",
    "#         b_input_ids = batch[0].to(device)\n",
    "#         b_input_mask = batch[1].to(device)\n",
    "#         b_labels = batch[2].to(device)\n",
    "\n",
    "#         # Always clear any previously calculated gradients before performing a\n",
    "#         # backward pass.\n",
    "#         model.zero_grad()        \n",
    "\n",
    "#         # Perform a forward pass (evaluate the model on this training batch).\n",
    "#         outputs = model(b_input_ids, \n",
    "#                     token_type_ids=None, \n",
    "#                     attention_mask=b_input_mask, \n",
    "#                     labels=b_labels)\n",
    "        \n",
    "#         # The call to `model` always returns a tuple, so we need to pull the \n",
    "#         # loss value out of the tuple.\n",
    "#         loss = outputs[0]\n",
    "\n",
    "#         # Accumulate the training loss over all of the batches so that we can\n",
    "#         # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "#         # single value; the `.item()` function just returns the Python value \n",
    "#         # from the tensor.\n",
    "#         total_loss += loss.item()\n",
    "\n",
    "#         # Perform a backward pass to calculate the gradients.\n",
    "#         loss.backward()\n",
    "\n",
    "#         # Clip the norm of the gradients to 1.0.\n",
    "#         # This is to help prevent the \"exploding gradients\" problem.\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "#         # Update parameters and take a step using the computed gradient.\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # Update the learning rate.\n",
    "#         scheduler.step()\n",
    "\n",
    "#     # Calculate the average loss over the training data.\n",
    "#     avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "#     # Store the loss value for plotting the learning curve.\n",
    "#     loss_values.append(avg_train_loss)\n",
    "\n",
    "#     print(\"\")\n",
    "#     print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "#     print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "#     # ========================================\n",
    "#     #                 Validation\n",
    "#     # ========================================\n",
    "#     # After the completion of each training epoch, measure our performance on\n",
    "#     # our validation set.\n",
    "\n",
    "#     print(\"\")\n",
    "#     print(\"Running validation...\")\n",
    "\n",
    "#     t0 = time.time()\n",
    "\n",
    "#     # Put the model in evaluation mode--the dropout layers behave differently\n",
    "#     # during evaluation.\n",
    "#     model.eval()\n",
    "\n",
    "#     # Tracking variables \n",
    "#     eval_loss, eval_accuracy = 0, 0\n",
    "#     nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "#     # Evaluate data for one epoch\n",
    "#     for batch in validation_dataloader:\n",
    "        \n",
    "#         # Add batch to GPU\n",
    "#         batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "#         # Unpack the inputs from our dataloader\n",
    "#         b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "#         # Telling the model not to compute or store gradients, saving memory and\n",
    "#         # speeding up validation\n",
    "#         with torch.no_grad():        \n",
    "\n",
    "#             # Forward pass, calculate logit predictions.\n",
    "#             # This will return the logits rather than the loss because we have\n",
    "#             # not provided labels.\n",
    "#             outputs = model(b_input_ids, \n",
    "#                             token_type_ids=None, \n",
    "#                             attention_mask=b_input_mask)\n",
    "        \n",
    "#         # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "#         # values prior to applying an activation function like the softmax.\n",
    "#         logits = outputs[0]\n",
    "\n",
    "#         # Move logits and labels to CPU\n",
    "#         logits = logits.detach().cpu().numpy()\n",
    "#         label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "#         # Calculate the accuracy for this batch of validation sentences.\n",
    "#         tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "#         # Accumulate the total accuracy.\n",
    "#         eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "#         # Track the number of batches\n",
    "#         nb_eval_steps += 1\n",
    "\n",
    "#     # Report the final accuracy for this validation run.\n",
    "#     print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "#     print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "# print(\"\")\n",
    "# print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Increase the plot size and font size.\n",
    "# plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# # Plot the learning curve.\n",
    "# plt.plot(loss_values, 'b-o')\n",
    "\n",
    "# # Label the plot.\n",
    "# plt.title(\"Training loss\")\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform training on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "train_inputs = torch.tensor(input_ids)\n",
    "train_labels = torch.tensor(labels)\n",
    "train_masks = torch.tensor(attention_masks)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels = len(label_dict), # The number of output labels \n",
    "    output_attentions = False, # Whether the model returns attention weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# comment this to do fine-tuning, otherwise we do transfer learning\n",
    "# for name, param in model.named_parameters():\n",
    "# \tif 'classifier' not in name: # classifier layer\n",
    "# \t\tparam.requires_grad = False\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, we set it at 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n",
    "\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "EPOCHS = 30\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * EPOCHS\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 2.42\n",
      "  Training epoch took: 0:00:12\n",
      "\n",
      "======== Epoch 2 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 2.09\n",
      "  Training epoch took: 0:00:12\n",
      "\n",
      "======== Epoch 3 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.74\n",
      "  Training epoch took: 0:00:12\n",
      "\n",
      "======== Epoch 4 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.38\n",
      "  Training epoch took: 0:00:13\n",
      "\n",
      "======== Epoch 5 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.01\n",
      "  Training epoch took: 0:00:13\n",
      "\n",
      "======== Epoch 6 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.70\n",
      "  Training epoch took: 0:00:13\n",
      "\n",
      "======== Epoch 7 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.46\n",
      "  Training epoch took: 0:00:13\n",
      "\n",
      "======== Epoch 8 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.28\n",
      "  Training epoch took: 0:00:13\n",
      "\n",
      "======== Epoch 9 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.18\n",
      "  Training epoch took: 0:00:13\n",
      "\n",
      "======== Epoch 10 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.11\n",
      "  Training epoch took: 0:00:13\n",
      "\n",
      "======== Epoch 11 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.07\n",
      "  Training epoch took: 0:00:13\n",
      "\n",
      "======== Epoch 12 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.06\n",
      "  Training epoch took: 0:00:13\n",
      "\n",
      "======== Epoch 13 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epoch took: 0:00:14\n",
      "\n",
      "======== Epoch 14 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epoch took: 0:00:14\n",
      "\n",
      "======== Epoch 15 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epoch took: 0:00:14\n",
      "\n",
      "======== Epoch 16 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epoch took: 0:00:14\n",
      "\n",
      "======== Epoch 17 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epoch took: 0:00:14\n",
      "\n",
      "======== Epoch 18 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epoch took: 0:00:14\n",
      "\n",
      "======== Epoch 19 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epoch took: 0:00:14\n",
      "\n",
      "======== Epoch 20 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epoch took: 0:00:13\n",
      "\n",
      "======== Epoch 21 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epoch took: 0:00:13\n",
      "\n",
      "======== Epoch 22 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epoch took: 0:00:13\n",
      "\n",
      "======== Epoch 23 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epoch took: 0:00:13\n",
      "\n",
      "======== Epoch 24 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epoch took: 0:00:13\n",
      "\n",
      "======== Epoch 25 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epoch took: 0:00:14\n",
      "\n",
      "======== Epoch 26 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epoch took: 0:00:14\n",
      "\n",
      "======== Epoch 27 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epoch took: 0:00:14\n",
      "\n",
      "======== Epoch 28 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epoch took: 0:00:14\n",
      "\n",
      "======== Epoch 29 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:00:14\n",
      "\n",
      "======== Epoch 30 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:00:14\n"
     ]
    }
   ],
   "source": [
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, EPOCHS):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, EPOCHS))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    # Put the model into training mode.\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass.\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        # The call to `model` always returns a tuple, so we need to pull the \n",
    "        # loss value out of the tuple.\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(loss_values, 'b-o')\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = load_data(\"data/test_shuffle.txt\")\n",
    "\n",
    "test_sentences = test_df['text'].values\n",
    "\n",
    "test_tokenized = tokenizer(test_sentences.tolist(), padding=\"max_length\", max_length=MAX_LEN, truncation=True)\n",
    "test_input_ids = test_tokenized['input_ids']\n",
    "test_attention_masks = test_tokenized['attention_mask']\n",
    "\n",
    "test_inputs = torch.tensor(test_input_ids)\n",
    "test_masks = torch.tensor(test_attention_masks)\n",
    "\n",
    "# Create the DataLoader for our test set.\n",
    "test_data = TensorDataset(test_inputs, test_masks)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 72/72 [00:10<00:00,  6.73it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Running on test data...\")\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "preds = np.array([])\n",
    "\n",
    "for batch in tqdm(test_dataloader):\n",
    "    \n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask = batch\n",
    "    \n",
    "    # Telling the model not to compute or store gradients, saving memory and\n",
    "    # speeding up validation\n",
    "    with torch.no_grad():        \n",
    "\n",
    "        # Forward pass, calculate logit predictions.\n",
    "        # This will return the logits rather than the loss because we have\n",
    "        # not provided labels.\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "    \n",
    "    # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "    # values prior to applying an activation function like the softmax.\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    \n",
    "    preds = np.concatenate([preds, np.argmax(logits, axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1140,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Environment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Environment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label\n",
       "0      Finance\n",
       "1  Environment\n",
       "2      Science\n",
       "3      Finance\n",
       "4  Environment"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.DataFrame(preds, columns=[\"label\"], dtype=int)\n",
    "pred_df[\"label\"] = pred_df[\"label\"].apply(lambda x: reverse_label_dict[x])\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv(\"data/submission.csv\", index=True, header=True, index_label=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
